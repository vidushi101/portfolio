[{"content":"Credentials ðŸ”— Certificate ðŸ”— Credly Badge Details I\u0026rsquo;ve passed the Google Data Analytics Professional Certificate - An 8-course long certification while working full-time as a Solutions Analyst.\nWhat is Google Data Analytics Professional Certificate? Google has provided a professional path to a career in data analytics. In this program, one learns in-demand skills to have you job-ready in less than 6 months.\nApplied Learning Project This program includes over 180 hours of instruction and hundreds of practice-based assessments, which will help you simulate real-world data analytics scenarios that are critical for success in the workplace. The content is highly interactive and exclusively developed by Google employees with decades of experience in data analytics. Through a mix of videos, assessments, and hands-on labs, youâ€™ll get introduced to analysis tools and platforms and key analytical skills required for an entry-level job.\nSkills youâ€™ll gain will include: Data cleaning, problem solving, critical thinking, data ethics, and data visualization\nPlatforms and tools you will learn include: Presentations, Spreadsheets, SQL, Tableau and R Programming\nIn addition to expert training and hands-on projects, you\u0026rsquo;ll complete a case study that you can share with potential employers to showcase your new skill set. Learn concrete skills that top employers are hiring for right now.\nSkills Learned Gained an immersive understanding of the practices and processes used by a junior or associate data analyst in their day-to-day job.\nLearned key analytical skills (data cleaning, analysis, \u0026amp; visualization) and tools (spreadsheets, SQL, R programming, Tableau)\nUnderstood how to clean and organize data for analysis, and complete analysis and calculations using spreadsheets, SQL and R programming\nLearn how to visualize and present data findings in dashboards, presentations and commonly used visualization platforms\nCourse 1: Foundations: Data, Data, Everywhere Course 2: Ask Questions to Make Data-Driven Decisions Course 3: Process Data from Dirty to Clean Course 4: Analyze Data to Answer Questions Course 5: Share Data Through the Art of Visualization Course 6: Data Analysis with R Programming Course 7: Data Analysis with R Programming Course 8: Google Data Analytics Capstone: Complete a Case Study ","permalink":"https://vidushikhanna.netlify.app/certifications/analyst/","summary":"Credentials ðŸ”— Certificate ðŸ”— Credly Badge Details I\u0026rsquo;ve passed the Google Data Analytics Professional Certificate - An 8-course long certification while working full-time as a Solutions Analyst.\nWhat is Google Data Analytics Professional Certificate? Google has provided a professional path to a career in data analytics. In this program, one learns in-demand skills to have you job-ready in less than 6 months.\nApplied Learning Project This program includes over 180 hours of instruction and hundreds of practice-based assessments, which will help you simulate real-world data analytics scenarios that are critical for success in the workplace.","title":"Data Analytics Professional Certificate"},{"content":"Credentials\nðŸ”— Certificate Details Microsoft Excel is an important tool for data analysis. It helps companies accurately assess situations and make better business decisions. This course helps you unlock the power of your organization\u0026rsquo;s data using the data analysis and visualization tools built into Excel. Author Curt Frye starts with the foundational concepts, including basic calculations such as mean, median, and standard deviation, and provides an introduction to the central limit theorem. He then shows how to visualize data, relationships, and future results with Excel\u0026rsquo;s histograms, graphs, and charts. He also covers testing hypotheses, modeling different data distributions, and calculating the covariance and correlation between data sets. Finally, he reviews the process of calculating Bayesian probabilities in Excel. Each chapter includes practical examples that show how to apply the techniques to real-world business problems.\n","permalink":"https://vidushikhanna.netlify.app/certifications/learning_excel/","summary":"Credentials\nðŸ”— Certificate Details Microsoft Excel is an important tool for data analysis. It helps companies accurately assess situations and make better business decisions. This course helps you unlock the power of your organization\u0026rsquo;s data using the data analysis and visualization tools built into Excel. Author Curt Frye starts with the foundational concepts, including basic calculations such as mean, median, and standard deviation, and provides an introduction to the central limit theorem.","title":"Learning Excel: Data Analysis"},{"content":"Credentials\nðŸ”— Certificate Details In this 1-hour 30-mins long project-based course, you will learn the responsibilities of a Business Analyst such as Learn the basic concepts of data analysis and descriptive statistics. Learn how to manipulate, analyze, and visualize data in Google Sheets using functions, aggregation functions, and logical aggregation functions. and present data using different types of charts.\nThis course works best for learners who wish to learn about Business Analysis and wish to learn about the role of a Business Analyst.\n","permalink":"https://vidushikhanna.netlify.app/certifications/spreadsheet_project/","summary":"Credentials\nðŸ”— Certificate Details In this 1-hour 30-mins long project-based course, you will learn the responsibilities of a Business Analyst such as Learn the basic concepts of data analysis and descriptive statistics. Learn how to manipulate, analyze, and visualize data in Google Sheets using functions, aggregation functions, and logical aggregation functions. and present data using different types of charts.\nThis course works best for learners who wish to learn about Business Analysis and wish to learn about the role of a Business Analyst.","title":"Introduction to Business Analysis Using Spreadsheets"},{"content":"Details Develop a clear and structured approach that will guide you through understanding not just how to use data science and machine learning libraries, but why we use them. This course is balanced between practical real world case studies and mathematical theory behind the machine learning algorithms.\nDeveloping the essential Python skillset Programming with Python NumPy with Python Deep dive into Pandas for Data Analysis Full understanding of Matplotlib Programming Library Deep dive into seaborn for data visualizations Machine Learning with SciKit Learn, including: Linear Regression Regularization Lasso Regression Ridge Regression Elastic Net K Nearest Neighbors K Means Clustering Decision Trees Random Forests Natural Language Processing Support Vector Machines Hierarchal Clustering DBSCAN PCA Model Deployment ","permalink":"https://vidushikhanna.netlify.app/certifications/python_boot/","summary":"Details Develop a clear and structured approach that will guide you through understanding not just how to use data science and machine learning libraries, but why we use them. This course is balanced between practical real world case studies and mathematical theory behind the machine learning algorithms.\nDeveloping the essential Python skillset Programming with Python NumPy with Python Deep dive into Pandas for Data Analysis Full understanding of Matplotlib Programming Library Deep dive into seaborn for data visualizations Machine Learning with SciKit Learn, including: Linear Regression Regularization Lasso Regression Ridge Regression Elastic Net K Nearest Neighbors K Means Clustering Decision Trees Random Forests Natural Language Processing Support Vector Machines Hierarchal Clustering DBSCAN PCA Model Deployment ","title":"2022 Python for Machine Learning \u0026 Data Science Masterclass"},{"content":"Intro In my video about How I cleared the AWS SAA Certification Exam, I shared my preparation strategy as well as tips to ace the exam. I also gave a glimpse of my revision notes that I prepared while taking the course and practice exams on Udemy. After that video was out, I got so many comments and DMs, requesting me to share my notes, but the problem was that I took these notes using a note-taking app called Obsidian which stores them in markdown format locally on my Mac. Once I\u0026rsquo;m done editing my notes, I push them to a GitHub repository to make sure I don\u0026rsquo;t lose them if my laptop breaks.\nSo, if you want to view my notes exactly like I do, you can clone my Obsidian Vault repository and download Obsidian to render it. But, this solution isn\u0026rsquo;t elegant as it would require you to download an additional software. So, I along with my college roommate, Sarthak Narayan, had been working over the past 2 weeks on the project, Obsidian Publish using GitHub Action, which would allow us to effortlessly publish our notes as a static website.\nIt is complete and I\u0026rsquo;ve used it to publish my notes at notes.arkalim.org. Working The GitHub Action spins up a Docker container which parses and converts Obsidian markdown notes into a special markdown format understood by MkDocs, an open-source static site generator. MkDocs is actually meant for preparing documentations but works well for notes too. After the markdown files have been converted, all the images in my notes are compressed to a fraction of their original size so that they can load quickly in your web browser. A static site is then built using MkDocs and then finally deployed on Netlify. All of this happens automatically using GitHub Actions. All I have to do is update my notes and push the changes to GitHub.\nFinal thoughts Having an automated way to publish your notes online with the community is a powerful way to share knowledge. This project has also made it exceedingly easy for me to refer my notes from anywhere, which is powerful when you work on a lot of systems.\nResources My Notes Obsidian Publish - GitHub Action Parser and Image Compressor MkDocs - Material Theme ","permalink":"https://vidushikhanna.netlify.app/projects/obsidian-publish-github-action/","summary":"Intro In my video about How I cleared the AWS SAA Certification Exam, I shared my preparation strategy as well as tips to ace the exam. I also gave a glimpse of my revision notes that I prepared while taking the course and practice exams on Udemy. After that video was out, I got so many comments and DMs, requesting me to share my notes, but the problem was that I took these notes using a note-taking app called Obsidian which stores them in markdown format locally on my Mac.","title":"Obsidian Publish using GitHub Action"},{"content":"ðŸ”— GitHub Description An app built to sync book highlights taken on Kindle E-Reader to Notion, my productivity management app of choice. The highlights are exported to a text file by Kindle, which is parsed by the app using RegEx to be sent to Notion. The app is written in TypeScript and involves interfacing with Notion API to perform CRUD operations on Notion Database. The app also features caching to prevent resyncing of old highlights.\n","permalink":"https://vidushikhanna.netlify.app/projects/kindle-to-notion/","summary":"ðŸ”— GitHub Description An app built to sync book highlights taken on Kindle E-Reader to Notion, my productivity management app of choice. The highlights are exported to a text file by Kindle, which is parsed by the app using RegEx to be sent to Notion. The app is written in TypeScript and involves interfacing with Notion API to perform CRUD operations on Notion Database. The app also features caching to prevent resyncing of old highlights.","title":"Kindle to Notion"},{"content":"ðŸ”— Colab Notebook Description In this project, I implemented the paper Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. The neural network, a combination of CNN and LSTM, was trained on the MS COCO dataset and it learns to generate captions from images.\nAs the network generates the caption, word by word, the modelâ€™s gaze (attention) shifts across the image. This allows it to focus on those parts of the image which is more relevant for the next word to be generated. Furthermore, beam search is used during inference to enhance the prediction result. The network was trained in PyTorch on an Nvidia GTX 1060 graphics card for over 80 epochs.\n","permalink":"https://vidushikhanna.netlify.app/projects/automated-image-captioning/","summary":"ðŸ”— Colab Notebook Description In this project, I implemented the paper Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. The neural network, a combination of CNN and LSTM, was trained on the MS COCO dataset and it learns to generate captions from images.\nAs the network generates the caption, word by word, the modelâ€™s gaze (attention) shifts across the image. This allows it to focus on those parts of the image which is more relevant for the next word to be generated.","title":"Automated Image Captioning (Bachelor Thesis)"},{"content":"ðŸ”— View App ðŸ”— GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.\n","permalink":"https://vidushikhanna.netlify.app/projects/todo-list-app/","summary":"ðŸ”— View App ðŸ”— GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.","title":"Todo List App"},{"content":"ðŸ”— Colab Notebook ðŸ”— Blog Post Description In this project, I trained a neural network to localize key points on faces. Resnet-18 was used as the model with some slight modifications to the input and output layer. The model was trained on the official DLib Dataset containing 6666 images along with corresponding 68-point landmarks for each face. Additionally, I wrote a custom data preprocessing pipeline in PyTorch to increase variance in the input images to help the model generalize better. The neural network was trained for 30 epochs before it reached the optima.\nDuring inference, OpenCV Harr Cascades are used to detect faces in the input images. Detected faces are then cropped, resized to (224, 224), and fed to our trained neural network to predict landmarks in them. The predicted landmarks in the cropped faces are then overlayed on top of the original image.\n","permalink":"https://vidushikhanna.netlify.app/projects/face-landmarks-detection/","summary":"ðŸ”— Colab Notebook ðŸ”— Blog Post Description In this project, I trained a neural network to localize key points on faces. Resnet-18 was used as the model with some slight modifications to the input and output layer. The model was trained on the official DLib Dataset containing 6666 images along with corresponding 68-point landmarks for each face. Additionally, I wrote a custom data preprocessing pipeline in PyTorch to increase variance in the input images to help the model generalize better.","title":"Face Landmarks Detection using CNN"},{"content":"Description The aim of the project was to build goggles which could find where the user was looking (gaze), the category of object the user was looking at, and the duration of attention on that object. The goggles had 3 camera modules, one on each eye to track the pupil movement and the third one for mapping the gaze to the real world. Thresholding was used to detect the pupils and contours were used to find its centre. Various important parameters such as pupil velocity, acceleration, and fixation time were calculated for further statistical analysis. Single Shot Descriptor, with VGG16 as backbone, was used to detect the objects the user was gazing at. Additionally, a GUI was made using TkInter for ease of use.\n","permalink":"https://vidushikhanna.netlify.app/projects/gaze-tracking-goggles/","summary":"Description The aim of the project was to build goggles which could find where the user was looking (gaze), the category of object the user was looking at, and the duration of attention on that object. The goggles had 3 camera modules, one on each eye to track the pupil movement and the third one for mapping the gaze to the real world. Thresholding was used to detect the pupils and contours were used to find its centre.","title":"Gaze-tracking Goggles"},{"content":"ðŸ”— GitHub Description The aim of the project is to build an open-source quadcopter platform for research in the field of drone autonomy. Various deep learning and computer vision algorithms will be implemented on the drone including person tracking, gesture control using human pose estimation, optical flow stabilization, obstacle avoidance, and depth estimation using monocular vision. The drone uses a Pixhawk flight controller with Raspberry Pi as a companion computer. DJI Flame Wheel-450 is used for the quadcopter frame along with some custom mountings for adding additional components.\nRaspberry Pi runs a ROS node which communicates with another ROS node running on the host PC to transfer videos over Wi-Fi. To make the project open-source, easy to develop, and easily reproducible, the simulation environment setup has been dockerized using docker container. We are currently developing the algorithms and testing them in Gazebo Simulation.\n","permalink":"https://vidushikhanna.netlify.app/projects/openquad/","summary":"ðŸ”— GitHub Description The aim of the project is to build an open-source quadcopter platform for research in the field of drone autonomy. Various deep learning and computer vision algorithms will be implemented on the drone including person tracking, gesture control using human pose estimation, optical flow stabilization, obstacle avoidance, and depth estimation using monocular vision. The drone uses a Pixhawk flight controller with Raspberry Pi as a companion computer. DJI Flame Wheel-450 is used for the quadcopter frame along with some custom mountings for adding additional components.","title":"OpenQuad"},{"content":" Presented in the 4th International and 19th National Conference on Machine and Mechanisms (iNaCoMM 2019)\nPublished in the Springer 2019\nðŸ”— Publication Description Natural disasters like earthquakes and landslides are sudden events that cause widespread destruction and major collateral damage including loss of life. Though disasters can never be prevented, their effects on mankind can surely be reduced. In this paper, we present the design and control of SRR (Search and Reconnaissance Robot), a robot capable of traversing on all terrains and locating survivors stuck under the debris. This will assist the rescue team to focus on recovering the victims, leaving the locating task for the Robots. The unique features of the SRR above existing ATVs are active-articulation, modularity, and assisted-autonomy. Active-articulation allows the SRR to climb objects much tall than itself. Modularity allows the SRR to detach into smaller modules to enter tight spaces where the whole body canâ€™t fit. Assisted-autonomy allows the SRR to detect the presence of objects in front and climb autonomously over them.\n","permalink":"https://vidushikhanna.netlify.app/projects/search-and-reconnaissance-robot/","summary":"Presented in the 4th International and 19th National Conference on Machine and Mechanisms (iNaCoMM 2019)\nPublished in the Springer 2019\nðŸ”— Publication Description Natural disasters like earthquakes and landslides are sudden events that cause widespread destruction and major collateral damage including loss of life. Though disasters can never be prevented, their effects on mankind can surely be reduced. In this paper, we present the design and control of SRR (Search and Reconnaissance Robot), a robot capable of traversing on all terrains and locating survivors stuck under the debris.","title":"Search and Reconnaissance Robot"},{"content":"Description I worked on this project single-handedly during the summer break following my freshman year at NIT- Trichy. SEBART-Pro is a robot that follows a ball while balancing on two wheels. It can also recognize traffic signs and act accordingly. It has two stepper motors for precise position control and used an Arduino Nano as the microcontroller. The robot senses the tilt using an MPU-6050 (6-axis gyroscope and accelerometer) and converts the values from these sensors into angles using a Kalman Filter. It uses the PID control algorithm to balance on two wheels and a simple Convolutional Neural Network is used to recognize traffic signs.\n","permalink":"https://vidushikhanna.netlify.app/projects/sebart-pro/","summary":"Description I worked on this project single-handedly during the summer break following my freshman year at NIT- Trichy. SEBART-Pro is a robot that follows a ball while balancing on two wheels. It can also recognize traffic signs and act accordingly. It has two stepper motors for precise position control and used an Arduino Nano as the microcontroller. The robot senses the tilt using an MPU-6050 (6-axis gyroscope and accelerometer) and converts the values from these sensors into angles using a Kalman Filter.","title":"SEBART-Pro"},{"content":"Description Developed an event-driven serverless integration framework using AWS services like AppFlow, S3, Lambda and EventBridge, to sync customer data between Salesforce and BuyerAssist. Through this, I learned to build systems to support bi-directional sync of large volumes of data from multiple sources, perform CRUD operations on MongoDB as well as schema design. Developed a configuration-driven framework to extend the pattern matching capability of AWS EventBridge, which prevented thousands of false invocations of AWS Lambda functions. Implemented a system to track asynchronous data transfer jobs through AWS AppFlow, which saved hours of debugging time. Developed a Salesforce app using SFDX to provide clients with a customized experience within their Salesforce dashboard. Developed a Slack bot to send interactive daily notifications to customers, and to allow them to take actions directly from Slack. This eliminated the operational resistance and increased the adoption of our product by over 50%. Implemented authorization for Slack integration with BuyerAssist using React and OAuth 2.0 Mentored a new recruit for a period of 1 month ","permalink":"https://vidushikhanna.netlify.app/experience/buyerassist/","summary":"Description Developed an event-driven serverless integration framework using AWS services like AppFlow, S3, Lambda and EventBridge, to sync customer data between Salesforce and BuyerAssist. Through this, I learned to build systems to support bi-directional sync of large volumes of data from multiple sources, perform CRUD operations on MongoDB as well as schema design. Developed a configuration-driven framework to extend the pattern matching capability of AWS EventBridge, which prevented thousands of false invocations of AWS Lambda functions.","title":"Backend Engineer"},{"content":"ðŸ”— GitHub Description Guide: Mohammad Farid Azampour (Visiting Researcher at Chair for Computer Aided Medical Procedures, TU Munich)\nMy work focused on using Pix2Pix (a CGAN architecture) to generate Ultrasound (US) scans from MRI scans, an image-to-image translation problem. However, a major challenge that I faced was the lack of structural correspondence between the MRI and US scans, arising from the sheer nature of the way this data is collected. Consequently, I wrote a custom loss function incorporating the CGAN loss with a Dice Loss between the segmentation maps obtained from the MRI scans and those from the generated US scan. This forces the generator to remove the structural deformation in the generated US scans. Additionally, I was given remote access to the TU-Munichâ€™s cluster computers for training the model as well as an account in their Discourse forum.\n","permalink":"https://vidushikhanna.netlify.app/experience/tumunich/","summary":"ðŸ”— GitHub Description Guide: Mohammad Farid Azampour (Visiting Researcher at Chair for Computer Aided Medical Procedures, TU Munich)\nMy work focused on using Pix2Pix (a CGAN architecture) to generate Ultrasound (US) scans from MRI scans, an image-to-image translation problem. However, a major challenge that I faced was the lack of structural correspondence between the MRI and US scans, arising from the sheer nature of the way this data is collected. Consequently, I wrote a custom loss function incorporating the CGAN loss with a Dice Loss between the segmentation maps obtained from the MRI scans and those from the generated US scan.","title":"Remote Research Intern"},{"content":"Description Guide: Dr. Sripad Krishna Devalla (co-founder and CTO at OriginHealth)\nI worked as a remote intern at OriginHealth Pte. Ltd. (Singapore), where the company envisions to automate the detection of birth defects from fetal ultrasound scans, a procedure that demands expertise in radiology.\nHere, I developed a configuration-driven framework with data preprocessing pipeline to train deep learning models on AWS EC2 instances. The framework standardized the training procedure for ML models and saved more than 100 hours of development time for the ML team. I also worked on fetal head segmentation using this framework.\nThis opportunity provided me with a deeper insight into the applications of AI and Computer Vision in medical diagnosis and taught me to work with little and sensitive data. In addition, Confluence was used for documentation and Jira Software was used for Agile Software Development.\n","permalink":"https://vidushikhanna.netlify.app/experience/origin-health/","summary":"Description Guide: Dr. Sripad Krishna Devalla (co-founder and CTO at OriginHealth)\nI worked as a remote intern at OriginHealth Pte. Ltd. (Singapore), where the company envisions to automate the detection of birth defects from fetal ultrasound scans, a procedure that demands expertise in radiology.\nHere, I developed a configuration-driven framework with data preprocessing pipeline to train deep learning models on AWS EC2 instances. The framework standardized the training procedure for ML models and saved more than 100 hours of development time for the ML team.","title":"Software Intern"},{"content":"ðŸ”— GitHub Description Guide: Prof. Dr. Pratyush Kumar (Assistant Professor, Dept. of Computer Science, IIT Madras)\nDuring my internship, I worked under the guidance of Prof. Pratyush Kumar (Assistant Professor, Department of Computer Science, IIT Madras) where I implemented a Convolutional Neural Network for 6-DoF Global Pose Regression and Odometry Estimation from consecutive monocular images. The model estimates the camera pose from a sequence of monocular images from the camera. At each step, the model takes two consecutive frames as input and returns the global and relative pose between the two frames. It was built and trained from scratch in Tensorflow and it outperformed traditional feature-based visual localization algorithms, especially in texture-less regions. The neural network was later used by Prof. Pratyush for the localization of robots in GPS denied environments.\n","permalink":"https://vidushikhanna.netlify.app/experience/iit-madras/","summary":"ðŸ”— GitHub Description Guide: Prof. Dr. Pratyush Kumar (Assistant Professor, Dept. of Computer Science, IIT Madras)\nDuring my internship, I worked under the guidance of Prof. Pratyush Kumar (Assistant Professor, Department of Computer Science, IIT Madras) where I implemented a Convolutional Neural Network for 6-DoF Global Pose Regression and Odometry Estimation from consecutive monocular images. The model estimates the camera pose from a sequence of monocular images from the camera. At each step, the model takes two consecutive frames as input and returns the global and relative pose between the two frames.","title":"Computer Vision Intern"}]